{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information for Users**\n",
    "\n",
    "- You must have an OpenAI Account and have an API key\n",
    "- You have to store this key in your windows environment or in your Google Colab as \"OPENAI_API_KEY\"\n",
    "- Without this key you won't be able to run this code \n",
    "- You have to install all necessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################  Importing Packages ######################### \n",
    "\n",
    "import os\n",
    "import openai\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import markdown2\n",
    "from tabulate import tabulate\n",
    "import re\n",
    "\n",
    "######################### Reading in Your OpenAI Key ######################### \n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()\n",
    "\n",
    "### If you use Google Colab, please use this code to read in your key:\n",
    "\n",
    "# from google.colab import userdata\n",
    "# key = userdata.get('OLSAI_API')\n",
    "# client = OpenAI(api_key = key)\n",
    "\n",
    "\n",
    "######################### Uploading the Dataset cacao.csv to the Client ######################### \n",
    "\n",
    "url = \"https://raw.githubusercontent.com/reyar/Statsomat/master/cacao.csv\"\n",
    "response = requests.get(url) \n",
    "filename = 'dataset.csv'\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "file = client.files.create(file=Path(filename),purpose='assistants')\n",
    "file_id = file.id\n",
    "\n",
    "#########################  Retrieving the OLSAI Assistent and Creating a Thread ######################### \n",
    "\n",
    "assistant_id = \"asst_hy4QCYQSm82ugjY98k3mxgYq\"\n",
    "olsai = client.beta.assistants.retrieve(assistant_id = assistant_id)\n",
    "thread = client.beta.threads.create()\n",
    "thread_id = thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Explain what descriptive statistics are. Do not refer to the dataset that i gave you.\",\n",
    "    \"Display the descriptive statistics of this dataset as a Markdown table with no other sentences.\",\n",
    "    \"Explain the summary statistics.\",\n",
    "    \"I want to know more about histograms: 1. What are histograms? 2. What are the components of a histogram? 3. How do i interpret a histogram? 4. Provide histograms for every variable of the dataset. Use 'sns.histplot(kde=True,color='gray')' to display the histograms in a grid format.\",\n",
    "    \"I want to know more about boxplots: 1. what are boxplots? 2. what are the components of a boxplots? 3. how do i interpret a boxplots? 4. Provide boxplots for every variable of the dataset. Use 'sns.boxplot(color='gray')' to display the boxplots in a grid format\",\n",
    "    \"I want to know more about ecdf plots: 1. what are ecdf plots? 2. what are the components of a ecdf plots? 3. how do i interpret a ecdf plots? 4. Provide ecdf plots for every variable of the dataset. Use 'sns.ecdfplot(color = 'black')' to display the ecdf plots in a grid format\",\n",
    "    \"I want to know more about qq plots: 1. what are qq plots? 2. what are the components of a qq plots? 3. how do i interpret a qq plots? 4. Provide qq plots for every variable of the dataset. Use 'stats.probplot(dist='norm')' to display the qq plots in a grid format\",\n",
    "    \"What is multiple linear regression? Use x_{ij} for independent variables. Explain the ranges of i and j. Explain the assumptions of a (classical) linear regression model in detail and simple, including mathematical equations. Do not provide additional considerations or methods for checking the assumptions. Summarize the assumptions in mathematical form.\",\n",
    "    \"Build an OLS regression model using stem_diameter as the dependent variable and all remaining variables as independent variables. Do not display the regression model summary or parameters.\",\n",
    "    \"Explain what Regression Diagnostics are without listing specific diagnostics or methods.\",\n",
    "    \"Explain outliers to me. Then, explain studentized residuals to me and provide mathematical equations. I want to understand the basic idea of studentized residuals. Afterwards, tell me which observation is an outlier by using the plot of studentized residuals vs index and 3 as threshold. Where does this threshold come from? Explain and interpret the plot. Should regression diagnostics be repeated after removing potential outliers? Additional infos on the plot: - annotate he outlier in the plot using only the index - use a red dashed line to show the threshold\",\n",
    "    \"Explain high-leverage points to me. Use 2p/n as threshold. Then, explain cooks distance to me and provide mathematical equations. I want to understand the basic idea of cooks distance.  Afterwards, tell me which observation is an high-leverage point by using the plot of leverage vs index using 2p/n as threshold and the plot of cooks distance vs index using 4/n as threshold. Do not make subplots. Explain and interpret the plots. Do not answer the question whether regression diagnostics be repeated after removing high-leverage points? Additional infos on the plot: - use black stemlines - use red stemlines for observations above the threshold and annotate them only using the index - use a red dashed line to show the threshold\",\n",
    "    \"Explain non-linearity to me. Then, explain the rainbow test to me and provide mathematical equations. I want to understand the basic idea of the rainbow test. Afterwards, tell me if non linearity if violated by using the rainbow test and the plot of residuals vs fitted values. Explain and interpret the plot. Additional infos on the plot: - use sns.residplot(lowess=True) and plt.scatter(predictions, residuals, color='black')\",\n",
    "    \"Explain heteroscedasticity to me in detail. Then, explain the breusch pangan test to me and provide mathematical equations. I want to understand the basic idea of the breusch pangan test. Afterwards, tell me if heteroscedasticity is violated by using the breusch pangan test and the scale location plot. Explain in detail and interpret the plot in detail. Additional infos on the plot: - use sns.regplot(lowess=True) and plt.scatter(predictions, sqrt_standardized_residuals, color='black') - no dashed line at 0\",\n",
    "    \"Explain correlation of error terms to me. Then, explain the durbin watson test to me and provide mathematical equations. I want to understand the basic idea of the durbin watson test. Afterwards, tell me if correlation of error terms is violated by using the durbin watson test with 1.5 - 2.5 as recommended range and the plot of residuals over time. Explain and interpret the plot.  Additional infos on the plot: - use plt.plot(studentized_residuals)\",\n",
    "    \"Explain normality of residuals to me. Then, explain the shapiro wilk test to me and provide mathematical equations. I want to understand the basic idea of the shapiro wilk test. Afterwards, tell me if non normality of residuals is violated by using the shapiro wilk test and the qq plot of standardized residuals. Explain and interpret the plot. Additional infos on the plot: - use stats.probplot(standardized_residuals, dist='norm', plot=plt)\",\n",
    "    \"Explain collinearity of predictors to me. Then, explain the variance inflation factor to me and provide mathematical equations. I want to understand the basic idea of the variance inflation factor. Afterwards, tell me if collinearity of predictors is violated by using the variance inflation factor with 10 as threshold and plot of the correlation matrix. Explain and interpret the plot. Explain how to read the plot. Additional infos on the plot: - use sns.heatmap(annot=True, cmap='coolwarm')\",\n",
    "    \"Summarize the results of outliers, high-leverage points, non-linearity, heteroscedasticity, correlation of error terms, normality of residuals and collinearity of predictors\"\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    status = \"incompleted\"  \n",
    "    while status != \"completed\": \n",
    "        message = client.beta.threads.messages.create( thread_id = thread_id, role = \"user\", content=prompt, attachments=[{\"file_id\": file_id, \"tools\": [{\"type\": \"code_interpreter\"}]}])\n",
    "        run = client.beta.threads.runs.create_and_poll(thread_id = thread.id, assistant_id = olsai.id, instructions = \"Adress the user as a student, who has no knowledge about data science.\")\n",
    "        status = run.status # NOCH EINBAUEN: Wenn Status incomplete, failed, ..., was dann?\n",
    "        \n",
    "response = client.beta.threads.messages.list(thread_id=thread.id, limit= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text1': '<p>Descriptive statistics are a set of brief descriptive coefficients that summarize a given data set, which can be either a representation of the entire population or a sample of a population. These statistics are broken down into measures of central tendency and measures of variability (spread).</p>\\n\\n<ol>\\n<li><p><strong>Measures of Central Tendency</strong>: These are used to describe the center of a data set. The most common measures are:</p>\\n\\n<ul>\\n<li><strong>Mean</strong>: The average of all data points.</li>\\n<li><strong>Median</strong>: The middle value when the data points are arranged in order.</li>\\n<li><strong>Mode</strong>: The most frequently occurring value in the data set.</li>\\n</ul></li>\\n<li><p><strong>Measures of Variability (Spread)</strong>: These describe the spread or dispersion of the data points. Common measures include:</p>\\n\\n<ul>\\n<li><strong>Range</strong>: The difference between the highest and lowest values.</li>\\n<li><strong>Variance</strong>: The average of the squared differences from the mean.</li>\\n<li><strong>Standard Deviation</strong>: The square root of the variance, representing the average distance of each data point from the mean.</li>\\n<li><strong>Interquartile Range (IQR)</strong>: The range between the first quartile (25th percentile) and the third quartile (75th percentile).</li>\\n</ul></li>\\n<li><p><strong>Other Descriptive Statistics</strong>:</p>\\n\\n<ul>\\n<li><strong>Skewness</strong>: A measure of the asymmetry of the data distribution.</li>\\n<li><strong>Kurtosis</strong>: A measure of the \"tailedness\" of the data distribution.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Descriptive statistics provide simple summaries about the sample and the measures. They form the basis of virtually every quantitative analysis of data.</p>\\n',\n",
       " 'text2': '<table>\\n  <tr><td>       </td><td>   ant_exclusion </td><td>   stem_diameter </td><td>   height </td><td>     canopy </td><td>   dw_healthy </td><td>   dw_infect </td><td>   dw_total </td><td>   fw_pulb </td><td>   fw_seeds </td><td>   fw_total </td><td>   ab_fl_op </td><td>   ab_fl_cl </td><td>    ab_fl </td></tr>\\n  <tr><td> count </td><td>      120        </td><td>       120       </td><td> 120      </td><td> 120        </td><td>       120    </td><td>     120     </td><td>    120     </td><td>     120   </td><td>     120    </td><td>      120   </td><td>    120     </td><td>     120    </td><td>   120    </td></tr>\\n  <tr><td> mean  </td><td>        0.5      </td><td>        27.0966  </td><td> 293      </td><td>   0.329775 </td><td>      1054.78 </td><td>     149.55  </td><td>   1203.53  </td><td>   16239.7 </td><td>    5404.45 </td><td>    21617.6 </td><td>   1550.13  </td><td>    3910.92 </td><td>  5452.61 </td></tr>\\n  <tr><td> std   </td><td>        0.502096 </td><td>         5.30599 </td><td>  34.6056 </td><td>   0.173708 </td><td>       750.21 </td><td>     146.953 </td><td>    824.982 </td><td>   10796.7 </td><td>    3541.42 </td><td>    14236.2 </td><td>    904.836 </td><td>    2230.83 </td><td>  3106.13 </td></tr>\\n  <tr><td> min   </td><td>        0        </td><td>        15.7375  </td><td> 223.75   </td><td>   0.015    </td><td>         0    </td><td>       0     </td><td>      0     </td><td>       0   </td><td>       0    </td><td>        0   </td><td>    241     </td><td>     741    </td><td>  1114    </td></tr>\\n  <tr><td> 25%   </td><td>        0        </td><td>        23.375   </td><td> 270.375  </td><td>   0.18125  </td><td>       447.25 </td><td>      46.75  </td><td>    573.25  </td><td>    8083.5 </td><td>    2824.25 </td><td>    11107.2 </td><td>    905.25  </td><td>    2277.5  </td><td>  3178.25 </td></tr>\\n  <tr><td> 50%   </td><td>        0.5      </td><td>        26.7125  </td><td> 287.875  </td><td>   0.344167 </td><td>       939.5  </td><td>     116     </td><td>   1135     </td><td>   14767   </td><td>    4983    </td><td>    19292   </td><td>   1360     </td><td>    3440.5  </td><td>  4798    </td></tr>\\n  <tr><td> 75%   </td><td>        1        </td><td>        30.3656  </td><td> 313.188  </td><td>   0.449167 </td><td>      1536    </td><td>     216.5   </td><td>   1717.5   </td><td>   21869.2 </td><td>    7544.5  </td><td>    29008.2 </td><td>   2018.75  </td><td>    5053.25 </td><td>  7006.75 </td></tr>\\n  <tr><td> max   </td><td>        1        </td><td>        46.6     </td><td> 399.5    </td><td>   0.708333 </td><td>      3045    </td><td>     920     </td><td>   3500     </td><td>   60787   </td><td>   17025    </td><td>    77812   </td><td>   4369     </td><td>   12469    </td><td> 16501    </td></tr>\\n</table>',\n",
       " 'text3': \"<p>The summary statistics provided in the table give us a snapshot of the dataset's characteristics. Here's a breakdown of what each row represents:</p>\\n\\n<ol>\\n<li><p><strong>Count</strong>: This indicates the number of observations in the dataset for each variable. In this case, each variable has 120 observations.</p></li>\\n<li><p><strong>Mean</strong>: The average value of each variable. It provides a central value for the data. For example, the mean of <code>stem_diameter</code> is approximately 27.10, indicating that the average stem diameter in the dataset is around this value.</p></li>\\n<li><p><strong>Standard Deviation (std)</strong>: This measures the amount of variation or dispersion in the dataset. A higher standard deviation indicates more spread out data. For instance, <code>fw_total</code> has a standard deviation of 14236.2, suggesting a wide range of values around the mean.</p></li>\\n<li><p><strong>Minimum (min)</strong>: The smallest value in the dataset for each variable. For example, the minimum <code>height</code> is 223.75.</p></li>\\n<li><p><strong>25th Percentile (25%)</strong>: Also known as the first quartile, this is the value below which 25% of the data falls. It helps in understanding the lower end of the data distribution.</p></li>\\n<li><p><strong>50th Percentile (50%)</strong>: Also known as the median, this is the middle value of the dataset, where half the data is below and half is above. For instance, the median <code>canopy</code> value is 0.344167.</p></li>\\n<li><p><strong>75th Percentile (75%)</strong>: Also known as the third quartile, this is the value below which 75% of the data falls. It helps in understanding the upper end of the data distribution.</p></li>\\n<li><p><strong>Maximum (max)</strong>: The largest value in the dataset for each variable. For example, the maximum <code>dw_healthy</code> is 3045.</p></li>\\n</ol>\\n\\n<p>These summary statistics provide a comprehensive overview of the dataset, allowing us to understand the central tendency, spread, and range of the data.</p>\\n\",\n",
       " 'text4': \"<ol>\\n<li><p><strong>What are histograms?</strong></p>\\n\\n<p>A histogram is a graphical representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable and was first introduced by Karl Pearson. A histogram is similar to a bar graph in structure; however, it groups numbers into ranges (bins) and displays the frequency of data points within each range.</p></li>\\n<li><p><strong>What are the components of a histogram?</strong></p>\\n\\n<ul>\\n<li><strong>Bins</strong>: These are the intervals that divide the entire range of values into a series of intervals. Each bin represents a range of data.</li>\\n<li><strong>Bars</strong>: Each bar represents the frequency (count) of data points that fall within each bin. The height of the bar indicates the number of data points in that bin.</li>\\n<li><strong>X-axis</strong>: This axis represents the variable being measured and is divided into bins.</li>\\n<li><strong>Y-axis</strong>: This axis represents the frequency of data points within each bin.</li>\\n</ul></li>\\n<li><p><strong>How do I interpret a histogram?</strong></p>\\n\\n<ul>\\n<li><strong>Shape</strong>: The shape of the histogram can indicate the distribution of the data (e.g., normal, skewed, bimodal).</li>\\n<li><strong>Spread</strong>: The width of the histogram shows the range of the data.</li>\\n<li><strong>Center</strong>: The peak of the histogram indicates where most data points are concentrated.</li>\\n<li><strong>Outliers</strong>: Bars that are isolated from the rest of the data may indicate outliers.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Let's create histograms for each variable in the dataset using the specified style.</p>\\n\",\n",
       " 'img5': 'image5.png',\n",
       " 'text5': \"<p>Here are the histograms for each variable in the dataset. Each plot shows the distribution of data points for a specific variable, with the bars representing the frequency of data points within each bin. The gray color and the KDE (Kernel Density Estimate) line help visualize the distribution's shape. You can interpret these histograms by looking at the shape, spread, center, and any potential outliers in the data.</p>\\n\",\n",
       " 'text6': \"<ol>\\n<li><p><strong>What are boxplots?</strong></p>\\n\\n<p>A boxplot, also known as a whisker plot, is a standardized way of displaying the distribution of data based on a five-number summary: minimum, first quartile (Q1), median, third quartile (Q3), and maximum. Boxplots are useful for identifying outliers and for comparing distributions between different sets of data.</p></li>\\n<li><p><strong>What are the components of a boxplot?</strong></p>\\n\\n<ul>\\n<li><strong>Box</strong>: The central box represents the interquartile range (IQR), which contains the middle 50% of the data. The edges of the box are the first quartile (Q1) and the third quartile (Q3).</li>\\n<li><strong>Median Line</strong>: A line inside the box indicates the median (the middle value) of the data.</li>\\n<li><strong>Whiskers</strong>: Lines extending from the box to the smallest and largest values within 1.5 times the IQR from the quartiles. They represent the range of the data excluding outliers.</li>\\n<li><strong>Outliers</strong>: Data points that fall outside the whiskers are considered outliers and are often plotted as individual points.</li>\\n</ul></li>\\n<li><p><strong>How do I interpret a boxplot?</strong></p>\\n\\n<ul>\\n<li><strong>Center</strong>: The median line inside the box shows the central tendency of the data.</li>\\n<li><strong>Spread</strong>: The length of the box (IQR) indicates the spread of the middle 50% of the data.</li>\\n<li><strong>Skewness</strong>: If the median is closer to the bottom or top of the box, it indicates skewness in the data.</li>\\n<li><strong>Outliers</strong>: Points outside the whiskers are potential outliers.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Let's create boxplots for each variable in the dataset using the specified style.</p>\\n\",\n",
       " 'img7': 'image7.png',\n",
       " 'text7': \"<p>Here are the boxplots for each variable in the dataset. Each plot provides a visual summary of the data's distribution, highlighting the median, quartiles, and potential outliers. You can interpret these boxplots by examining the central tendency, spread, skewness, and any outliers present in the data.</p>\\n\",\n",
       " 'text8': \"<ol>\\n<li><p><strong>What are ECDF plots?</strong></p>\\n\\n<p>An Empirical Cumulative Distribution Function (ECDF) plot is a graphical representation of the cumulative distribution of a dataset. It shows the proportion or count of observations falling below each unique value in a dataset. ECDF plots are useful for visualizing the distribution of data and comparing different datasets.</p></li>\\n<li><p><strong>What are the components of an ECDF plot?</strong></p>\\n\\n<ul>\\n<li><strong>X-axis</strong>: Represents the data values.</li>\\n<li><strong>Y-axis</strong>: Represents the cumulative proportion or count of observations. It ranges from 0 to 1 (or 0 to the total number of observations if using counts).</li>\\n<li><strong>Step Function</strong>: The ECDF is a step function that increases by 1/n (where n is the total number of observations) at each data point.</li>\\n</ul></li>\\n<li><p><strong>How do I interpret an ECDF plot?</strong></p>\\n\\n<ul>\\n<li><strong>Cumulative Proportion</strong>: The Y-axis value at a given X-axis value indicates the proportion of data points less than or equal to that value.</li>\\n<li><strong>Distribution Shape</strong>: The shape of the ECDF can give insights into the distribution of the data. A steep slope indicates a large number of observations in a small range, while a gradual slope indicates a more spread-out distribution.</li>\\n<li><strong>Comparisons</strong>: ECDF plots are particularly useful for comparing the distributions of different datasets.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Let's create ECDF plots for each variable in the dataset using the specified style.</p>\\n\",\n",
       " 'img9': 'image9.png',\n",
       " 'text9': '<p>Here are the ECDF plots for each variable in the dataset. Each plot shows the cumulative distribution of data points, with the X-axis representing the data values and the Y-axis representing the cumulative proportion of observations. You can interpret these plots by examining the cumulative proportion at different values, the shape of the distribution, and comparing distributions across different variables.</p>\\n',\n",
       " 'text10': \"<ol>\\n<li><p><strong>What are QQ plots?</strong></p>\\n\\n<p>A Quantile-Quantile (QQ) plot is a graphical tool to help assess if a dataset follows a particular distribution, most commonly the normal distribution. It compares the quantiles of the dataset against the quantiles of a theoretical distribution. If the data follows the distribution, the points will approximately lie on a straight line.</p></li>\\n<li><p><strong>What are the components of a QQ plot?</strong></p>\\n\\n<ul>\\n<li><strong>X-axis</strong>: Represents the theoretical quantiles from the specified distribution (e.g., normal distribution).</li>\\n<li><strong>Y-axis</strong>: Represents the quantiles of the dataset being tested.</li>\\n<li><strong>Line</strong>: A reference line (often a 45-degree line) that indicates where the points would fall if the data perfectly followed the theoretical distribution.</li>\\n</ul></li>\\n<li><p><strong>How do I interpret a QQ plot?</strong></p>\\n\\n<ul>\\n<li><strong>Linearity</strong>: If the points lie approximately along the reference line, the data likely follows the specified distribution.</li>\\n<li><strong>Deviations</strong>: Points deviating from the line indicate departures from the distribution. For example, points above the line in the tails suggest heavier tails than the theoretical distribution.</li>\\n<li><strong>Outliers</strong>: Points far from the line may indicate outliers in the data.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Let's create QQ plots for each variable in the dataset using the specified method.</p>\\n\",\n",
       " 'img11': 'image11.png',\n",
       " 'text11': '<p>Here are the QQ plots for each variable in the dataset. Each plot compares the quantiles of the dataset against the quantiles of a normal distribution. The black line represents the theoretical distribution, and the blue points represent the data. You can interpret these plots by examining how closely the points follow the line, which indicates how well the data fits the normal distribution. Deviations from the line suggest departures from normality, such as skewness or the presence of outliers.</p>\\n',\n",
       " 'text12': '<p>Multiple linear regression is a statistical technique used to model the relationship between one dependent variable and two or more independent variables. The goal is to find the best-fitting linear equation that describes how the dependent variable changes with the independent variables.</p>\\n\\n<h3>Model Representation</h3>\\n\\n<p>The multiple linear regression model can be represented as:</p>\\n\\n<p>\\\\( \\ny_i = \\\\beta_0 + \\\\beta_1 x_{i1} + \\\\beta_2 x_{i2} + \\\\cdots + \\\\beta_p x_{ip} + \\\\epsilon_i \\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( y_i \\\\) is the dependent variable for the \\\\( i \\\\)-th observation.</li>\\n<li>\\\\( \\\\beta_0 \\\\) is the intercept.</li>\\n<li>\\\\( \\\\beta_1, \\\\beta_2, \\\\ldots, \\\\beta_p \\\\) are the coefficients of the independent variables.</li>\\n<li>\\\\( x_{ij} \\\\) represents the \\\\( j \\\\)-th independent variable for the \\\\( i \\\\)-th observation.</li>\\n<li>\\\\( \\\\epsilon_i \\\\) is the error term for the \\\\( i \\\\)-th observation.</li>\\n</ul>\\n\\n<h3>Ranges of \\\\( i \\\\) and \\\\( j \\\\)</h3>\\n\\n<ul>\\n<li>\\\\( i \\\\) ranges from 1 to \\\\( n \\\\), where \\\\( n \\\\) is the number of observations in the dataset.</li>\\n<li>\\\\( j \\\\) ranges from 1 to \\\\( p \\\\), where \\\\( p \\\\) is the number of independent variables.</li>\\n</ul>\\n\\n<h3>Assumptions of a (Classical) Linear Regression Model</h3>\\n\\n<ol>\\n<li><p><strong>Linearity</strong>: The relationship between the dependent variable and the independent variables is linear. This means the change in the dependent variable is proportional to the change in the independent variables.</p>\\n\\n<p>\\\\(\\nE(y_i | x_{i1}, x_{i2}, \\\\ldots, x_{ip}) = \\\\beta_0 + \\\\beta_1 x_{i1} + \\\\beta_2 x_{i2} + \\\\cdots + \\\\beta_p x_{ip}\\n\\\\)</p></li>\\n<li><p><strong>Independence</strong>: The observations are independent of each other. This means the value of the dependent variable for one observation is not influenced by the value for another observation.</p></li>\\n<li><p><strong>Homoscedasticity</strong>: The variance of the error terms (\\\\( \\\\epsilon_i \\\\)) is constant across all levels of the independent variables.</p>\\n\\n<p>\\\\(\\n\\\\text{Var}(\\\\epsilon_i) = \\\\sigma^2 \\\\quad \\\\text{for all } i\\n\\\\)</p></li>\\n<li><p><strong>Normality</strong>: The error terms (\\\\( \\\\epsilon_i \\\\)) are normally distributed.</p>\\n\\n<p>\\\\(\\n\\\\epsilon_i \\\\sim N(0, \\\\sigma^2)\\n\\\\)</p></li>\\n<li><p><strong>No Multicollinearity</strong>: The independent variables are not perfectly correlated with each other. This means no independent variable can be expressed as a linear combination of the others.</p></li>\\n</ol>\\n\\n<h3>Summary of Assumptions in Mathematical Form</h3>\\n\\n<ul>\\n<li>Linearity: \\\\( E(y_i | x_{i1}, x_{i2}, \\\\ldots, x_{ip}) = \\\\beta_0 + \\\\beta_1 x_{i1} + \\\\beta_2 x_{i2} + \\\\cdots + \\\\beta_p x_{ip} \\\\)</li>\\n<li>Independence: Observations are independent.</li>\\n<li>Homoscedasticity: \\\\( \\\\text{Var}(\\\\epsilon_i) = \\\\sigma^2 \\\\)</li>\\n<li>Normality: \\\\( \\\\epsilon_i \\\\sim N(0, \\\\sigma^2) \\\\)</li>\\n<li>No Multicollinearity: Independent variables are not perfectly correlated.</li>\\n</ul>\\n',\n",
       " 'text13': '<p>The OLS regression model has been successfully built using <code>stem_diameter</code> as the dependent variable and all other variables as independent variables. If you need further analysis or specific outputs from this model, feel free to ask!</p>\\n',\n",
       " 'text14': \"<p>Regression diagnostics are a set of procedures used to evaluate the validity and reliability of a regression model. These diagnostics help in assessing whether the assumptions of the regression model are met and whether the model provides a good fit to the data. They involve examining the residuals (the differences between observed and predicted values) and other aspects of the model to identify potential issues that could affect the model's performance.</p>\\n\\n<p>The purpose of regression diagnostics is to ensure that the model is appropriate for the data and that the conclusions drawn from the model are valid. By conducting these diagnostics, one can detect problems such as non-linearity, heteroscedasticity, multicollinearity, and influential data points, which may require adjustments to the model or data. This process is crucial for improving the model's accuracy and ensuring that the results are interpretable and reliable.</p>\\n\",\n",
       " 'text15': \"<h3>Outliers</h3>\\n\\n<p>Outliers are data points that differ significantly from other observations in a dataset. They can occur due to variability in the data, measurement errors, or other factors. Outliers can have a substantial impact on statistical analyses, including regression models, as they can skew results and affect the model's accuracy. Identifying and addressing outliers is an important step in data analysis to ensure the robustness of the conclusions drawn.</p>\\n\\n<h3>Studentized Residuals</h3>\\n\\n<p>Studentized residuals are a type of standardized residual used in regression analysis to identify outliers. They are calculated by dividing the residuals by an estimate of their standard deviation, which accounts for the variability of the residuals. This standardization allows for a more accurate assessment of whether a residual is unusually large or small.</p>\\n\\n<p>The formula for calculating the studentized residual for the \\\\(i\\\\)-th observation is:</p>\\n\\n<p>\\\\(\\nt_i = \\\\frac{e_i}{s(e_i)}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( t_i \\\\) is the studentized residual for the \\\\(i\\\\)-th observation.</li>\\n<li>\\\\( e_i \\\\) is the residual for the \\\\(i\\\\)-th observation (the difference between the observed and predicted value).</li>\\n<li>\\\\( s(e_i) \\\\) is the estimated standard deviation of the residual \\\\( e_i \\\\).</li>\\n</ul>\\n\\n<h3>Identifying Outliers with Studentized Residuals</h3>\\n\\n<p>A common threshold for identifying outliers using studentized residuals is 3. This threshold is based on the properties of the normal distribution, where approximately 99.7% of data points lie within three standard deviations of the mean. Therefore, a studentized residual greater than 3 (or less than -3) suggests that the observation is an outlier.</p>\\n\\n<p>Let's plot the studentized residuals against the index to identify any potential outliers in the dataset.</p>\\n\",\n",
       " 'img16': 'image16.png',\n",
       " 'text16': \"<p>The plot above shows the studentized residuals for each observation in the dataset. The red dashed lines represent the threshold of 3 and -3, which are commonly used to identify outliers. Observations with studentized residuals beyond these thresholds are considered potential outliers.</p>\\n\\n<p>In this case, observation with index 27 is identified as an outlier because its studentized residual exceeds the threshold of 3.</p>\\n\\n<h3>Interpretation of the Plot</h3>\\n\\n<ul>\\n<li><strong>Points within the Threshold</strong>: Most data points fall within the red dashed lines, indicating that they are not considered outliers.</li>\\n<li><strong>Points beyond the Threshold</strong>: The point at index 27 lies outside the threshold, suggesting it is an outlier.</li>\\n</ul>\\n\\n<h3>Should Regression Diagnostics be Repeated After Removing Potential Outliers?</h3>\\n\\n<p>Yes, it is generally advisable to repeat regression diagnostics after removing potential outliers. Outliers can have a significant impact on the model's parameters and assumptions. By removing them and re-evaluating the model, you can ensure that the model is robust and that the assumptions of linear regression are still valid. This process helps in improving the accuracy and reliability of the regression analysis.</p>\\n\",\n",
       " 'text17': \"<h3>High-Leverage Points</h3>\\n\\n<p>High-leverage points are observations in a dataset that have an unusual combination of independent variable values. These points can exert significant influence on the regression model's fit because they are located far from the center of the data distribution in the space of the independent variables. High-leverage points can potentially distort the results of a regression analysis.</p>\\n\\n<p>A common threshold for identifying high-leverage points is \\\\( \\\\frac{2p}{n} \\\\), where \\\\( p \\\\) is the number of parameters (including the intercept) in the model, and \\\\( n \\\\) is the number of observations. Observations with leverage values greater than this threshold are considered high-leverage points.</p>\\n\\n<h3>Cook's Distance</h3>\\n\\n<p>Cook's Distance is a measure used to identify influential data points in a regression model. It quantifies the effect of deleting a given observation on the estimated regression coefficients. A large Cook's Distance indicates that the observation has a significant impact on the model's fit.</p>\\n\\n<p>The formula for Cook's Distance for the \\\\(i\\\\)-th observation is:</p>\\n\\n<p>\\\\(\\nD_i = \\\\frac{\\\\sum_{j=1}^{n} (\\\\hat{y}_j - \\\\hat{y}_{j(i)})^2}{p \\\\cdot \\\\text{MSE}}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( D_i \\\\) is Cook's Distance for the \\\\(i\\\\)-th observation.</li>\\n<li>\\\\( \\\\hat{y}_j \\\\) is the predicted value for the \\\\(j\\\\)-th observation using the full dataset.</li>\\n<li>\\\\( \\\\hat{y}_{j(i)} \\\\) is the predicted value for the \\\\(j\\\\)-th observation when the \\\\(i\\\\)-th observation is removed.</li>\\n<li>\\\\( p \\\\) is the number of parameters in the model.</li>\\n<li>\\\\(\\\\text{MSE}\\\\) is the mean squared error of the model.</li>\\n</ul>\\n\\n<p>Let's plot the leverage values and Cook's Distance to identify high-leverage points and influential observations.</p>\\n\",\n",
       " 'img18': 'image18.png',\n",
       " 'img18_2': 'image18_2.png',\n",
       " 'text18': \"<h3>Interpretation of the Plots</h3>\\n\\n<h4>Leverage vs Index Plot</h4>\\n\\n<ul>\\n<li><strong>Black Stemlines</strong>: Represent the leverage values for each observation.</li>\\n<li><strong>Red Dashed Line</strong>: Indicates the leverage threshold (\\\\( \\\\frac{2p}{n} \\\\)).</li>\\n<li><strong>Red Stemlines and Annotations</strong>: Highlight observations with leverage values above the threshold, indicating high-leverage points. In this dataset, observations with indices [20, 22, 26, 30, 36, 37, 42, 58, 74, 76, 106] are identified as high-leverage points.</li>\\n</ul>\\n\\n<h4>Cook's Distance vs Index Plot</h4>\\n\\n<ul>\\n<li><strong>Black Stemlines</strong>: Represent Cook's Distance for each observation.</li>\\n<li><strong>Red Dashed Line</strong>: Indicates the Cook's Distance threshold (\\\\( \\\\frac{4}{n} \\\\)).</li>\\n<li><strong>Red Stemlines and Annotations</strong>: Highlight observations with Cook's Distance above the threshold, indicating influential points. In this dataset, observations with indices [12, 20, 22, 27, 34, 35, 36, 74, 76] are identified as influential points.</li>\\n</ul>\\n\\n<h3>Explanation</h3>\\n\\n<ul>\\n<li><strong>High-Leverage Points</strong>: These are observations that have a significant potential to influence the regression model due to their unusual combination of independent variable values. They are identified by their leverage values exceeding the threshold.</li>\\n<li><strong>Influential Points (Cook's Distance)</strong>: These are observations that have a substantial impact on the regression model's coefficients. They are identified by their Cook's Distance exceeding the threshold.</li>\\n</ul>\\n\\n<p>Both high-leverage and influential points can affect the stability and accuracy of a regression model, and it's important to consider their impact when interpreting the results.</p>\\n\",\n",
       " 'text19': \"<h3>Non-Linearity</h3>\\n\\n<p>Non-linearity refers to a situation where the relationship between the independent variables and the dependent variable in a regression model is not linear. In a linear regression model, it is assumed that changes in the independent variables lead to proportional changes in the dependent variable. However, if this assumption is violated, the model may not accurately capture the true relationship, leading to biased or misleading results.</p>\\n\\n<h3>Rainbow Test</h3>\\n\\n<p>The rainbow test is a statistical test used to detect non-linearity in a regression model. It assesses whether the relationship between the independent and dependent variables is linear by examining the distribution of residuals. The test involves splitting the data into two parts and comparing the fit of the model on these subsets to the fit on the entire dataset.</p>\\n\\n<p>The basic idea of the rainbow test is to check if the model's fit is consistent across different parts of the data. If the fit is significantly different, it suggests non-linearity.</p>\\n\\n<h4>Mathematical Representation</h4>\\n\\n<p>The rainbow test involves the following steps:</p>\\n\\n<ol>\\n<li>Fit the regression model to the entire dataset and calculate the residual sum of squares (RSS).</li>\\n<li>Split the dataset into two parts and fit the model to each subset.</li>\\n<li>Calculate the RSS for each subset.</li>\\n<li>Compare the RSS of the subsets to the RSS of the entire dataset using an F-test.</li>\\n</ol>\\n\\n<p>The test statistic is given by:</p>\\n\\n<p>\\\\(\\nF = \\\\frac{(RSS_{\\\\text{full}} - (RSS_1 + RSS_2)) / k}{(RSS_1 + RSS_2) / (n - 2k)}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( RSS_{\\\\text{full}} \\\\) is the residual sum of squares for the full dataset.</li>\\n<li>\\\\( RSS_1 \\\\) and \\\\( RSS_2 \\\\) are the residual sum of squares for the two subsets.</li>\\n<li>\\\\( k \\\\) is the number of parameters in the model.</li>\\n<li>\\\\( n \\\\) is the total number of observations.</li>\\n</ul>\\n\\n<p>Let's perform the rainbow test and plot the residuals vs. fitted values to check for non-linearity.</p>\\n\",\n",
       " 'img20': 'image20.png',\n",
       " 'text20': '<h3>Interpretation of the Rainbow Test</h3>\\n\\n<p>The rainbow test statistic is approximately 1.20, with a p-value of about 0.255. The p-value indicates the probability of observing the test statistic under the null hypothesis that the relationship is linear. A common threshold for significance is 0.05. Since the p-value is greater than 0.05, we do not have enough evidence to reject the null hypothesis, suggesting that non-linearity is not a significant issue in this model.</p>\\n\\n<h3>Interpretation of the Residuals vs. Fitted Values Plot</h3>\\n\\n<ul>\\n<li><strong>Blue Line</strong>: Represents a smoothed line through the residuals, helping to visualize any systematic patterns.</li>\\n<li><strong>Black Points</strong>: Represent the residuals for each observation plotted against the fitted values.</li>\\n<li><strong>Red Dashed Line</strong>: Represents the zero line, where residuals should ideally be centered if the model is appropriate.</li>\\n</ul>\\n\\n<p>In the plot, the residuals appear to be randomly scattered around the red dashed line, with no clear pattern or systematic deviation. This suggests that the assumption of linearity is reasonably met, as there is no strong evidence of non-linearity in the relationship between the independent variables and the dependent variable.</p>\\n\\n<p>Overall, both the rainbow test and the residuals plot indicate that non-linearity is not a significant concern for this regression model.</p>\\n',\n",
       " 'text21': \"<h3>Heteroscedasticity</h3>\\n\\n<p>Heteroscedasticity refers to a situation in regression analysis where the variance of the residuals (errors) is not constant across all levels of the independent variables. In a well-fitted linear regression model, the residuals should have constant variance, a condition known as homoscedasticity. When this condition is violated, it can lead to inefficient estimates and affect the validity of statistical tests, making it difficult to trust the conclusions drawn from the model.</p>\\n\\n<h3>Breusch-Pagan Test</h3>\\n\\n<p>The Breusch-Pagan test is a statistical test used to detect heteroscedasticity in a regression model. It examines whether the variance of the residuals is related to the independent variables. The basic idea is to test if the residual variance is constant or if it changes with the level of the independent variables.</p>\\n\\n<h4>Mathematical Representation</h4>\\n\\n<p>The Breusch-Pagan test involves the following steps:</p>\\n\\n<ol>\\n<li>Fit the regression model and obtain the residuals.</li>\\n<li>Regress the squared residuals on the independent variables.</li>\\n<li>Calculate the test statistic:</li>\\n</ol>\\n\\n<p>\\\\(\\nBP = \\\\frac{n \\\\cdot R^2}{2}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( BP \\\\) is the Breusch-Pagan test statistic.</li>\\n<li>\\\\( n \\\\) is the number of observations.</li>\\n<li>\\\\( R^2 \\\\) is the coefficient of determination from the regression of squared residuals on the independent variables.</li>\\n</ul>\\n\\n<p>The test statistic follows a chi-square distribution with degrees of freedom equal to the number of independent variables. A significant test statistic indicates heteroscedasticity.</p>\\n\\n<p>Let's perform the Breusch-Pagan test and create a scale-location plot to check for heteroscedasticity.</p>\\n\",\n",
       " 'img22': 'image22.png',\n",
       " 'text22': '<h3>Interpretation of the Breusch-Pagan Test</h3>\\n\\n<p>The Breusch-Pagan test statistic is approximately 19.68, with a p-value of about 0.073. The p-value indicates the probability of observing the test statistic under the null hypothesis that the variance of the residuals is constant (homoscedasticity). A common threshold for significance is 0.05. Since the p-value is greater than 0.05, we do not have enough evidence to reject the null hypothesis, suggesting that heteroscedasticity is not a significant issue in this model.</p>\\n\\n<h3>Interpretation of the Scale-Location Plot</h3>\\n\\n<ul>\\n<li><strong>Blue Line</strong>: Represents a smoothed line through the square root of the standardized residuals, helping to visualize any systematic patterns.</li>\\n<li><strong>Black Points</strong>: Represent the square root of the standardized residuals for each observation plotted against the fitted values.</li>\\n</ul>\\n\\n<p>In the plot, the square root of the standardized residuals appears to be randomly scattered around the fitted values, with no clear pattern or systematic deviation. This suggests that the variance of the residuals is relatively constant across different levels of the fitted values, indicating homoscedasticity.</p>\\n\\n<p>Overall, both the Breusch-Pagan test and the scale-location plot indicate that heteroscedasticity is not a significant concern for this regression model. The residuals appear to have a constant variance, supporting the assumption of homoscedasticity in the linear regression model.</p>\\n',\n",
       " 'text23': \"<h3>Correlation of Error Terms</h3>\\n\\n<p>In regression analysis, the assumption is that the error terms (residuals) are uncorrelated with each other. This means that the error for one observation should not be related to the error for another observation. When this assumption is violated, it indicates autocorrelation, which is often a concern in time series data where observations are collected over time. Autocorrelation can lead to inefficient estimates and affect the validity of statistical tests, making it difficult to trust the conclusions drawn from the model.</p>\\n\\n<h3>Durbin-Watson Test</h3>\\n\\n<p>The Durbin-Watson test is a statistical test used to detect the presence of autocorrelation in the residuals of a regression model. It specifically tests for first-order autocorrelation, which is the correlation between consecutive residuals.</p>\\n\\n<h4>Mathematical Representation</h4>\\n\\n<p>The Durbin-Watson test statistic is calculated as:</p>\\n\\n<p>\\\\(\\nDW = \\\\frac{\\\\sum_{i=2}^{n} (e_i - e_{i-1})^2}{\\\\sum_{i=1}^{n} e_i^2}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( DW \\\\) is the Durbin-Watson test statistic.</li>\\n<li>\\\\( e_i \\\\) is the residual for the \\\\(i\\\\)-th observation.</li>\\n<li>\\\\( n \\\\) is the number of observations.</li>\\n</ul>\\n\\n<p>The test statistic ranges from 0 to 4:</p>\\n\\n<ul>\\n<li>A value around 2 suggests no autocorrelation.</li>\\n<li>A value less than 2 indicates positive autocorrelation.</li>\\n<li>A value greater than 2 indicates negative autocorrelation.</li>\\n</ul>\\n\\n<p>A recommended range for the Durbin-Watson statistic is 1.5 to 2.5, suggesting no significant autocorrelation.</p>\\n\\n<p>Let's perform the Durbin-Watson test and plot the residuals over time to check for autocorrelation.</p>\\n\",\n",
       " 'img24': 'image24.png',\n",
       " 'text24': \"<h3>Interpretation of the Durbin-Watson Test</h3>\\n\\n<p>The Durbin-Watson test statistic is approximately 1.44. The recommended range for the Durbin-Watson statistic is 1.5 to 2.5, which suggests no significant autocorrelation. Since the test statistic is slightly below this range, it indicates a potential presence of positive autocorrelation in the residuals.</p>\\n\\n<h3>Interpretation of the Residuals Over Time Plot</h3>\\n\\n<ul>\\n<li><strong>Black Line</strong>: Represents the studentized residuals plotted over the index (which can be considered as time if the data is time-ordered).</li>\\n</ul>\\n\\n<p>In the plot, if the residuals show a clear pattern or trend over time, it suggests autocorrelation. In this case, the residuals do not appear to follow a random pattern, which aligns with the Durbin-Watson test result indicating potential positive autocorrelation.</p>\\n\\n<p>Overall, the Durbin-Watson test and the residuals plot suggest that there might be some degree of positive autocorrelation in the error terms, which could affect the reliability of the regression model's estimates.</p>\\n\",\n",
       " 'text25': \"<h3>Normality of Residuals</h3>\\n\\n<p>In regression analysis, one of the assumptions is that the residuals (errors) are normally distributed. This assumption is important because it underlies the validity of many statistical tests and confidence intervals. If the residuals are not normally distributed, it can affect the reliability of hypothesis tests and the accuracy of predictions.</p>\\n\\n<h3>Shapiro-Wilk Test</h3>\\n\\n<p>The Shapiro-Wilk test is a statistical test used to assess the normality of a dataset. It tests the null hypothesis that the data is normally distributed against the alternative hypothesis that it is not.</p>\\n\\n<h4>Mathematical Representation</h4>\\n\\n<p>The Shapiro-Wilk test statistic is calculated as:</p>\\n\\n<p>\\\\(\\nW = \\\\frac{\\\\left( \\\\sum_{i=1}^{n} a_i x_{(i)} \\\\right)^2}{\\\\sum_{i=1}^{n} (x_i - \\\\bar{x})^2}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( W \\\\) is the Shapiro-Wilk test statistic.</li>\\n<li>\\\\( x_{(i)} \\\\) are the ordered sample values.</li>\\n<li>\\\\( a_i \\\\) are constants generated from the means, variances, and covariances of the order statistics of a normal distribution.</li>\\n<li>\\\\( \\\\bar{x} \\\\) is the sample mean.</li>\\n</ul>\\n\\n<p>A small \\\\( W \\\\) value indicates a departure from normality. The test provides a p-value, and if it is below a chosen significance level (commonly 0.05), the null hypothesis of normality is rejected.</p>\\n\\n<p>Let's perform the Shapiro-Wilk test and create a QQ plot of the standardized residuals to check for normality.</p>\\n\",\n",
       " 'img26': 'image26.png',\n",
       " 'text26': '<h3>Interpretation of the Shapiro-Wilk Test</h3>\\n\\n<p>The Shapiro-Wilk test statistic is approximately 0.985, with a p-value of about 0.199. The p-value indicates the probability of observing the test statistic under the null hypothesis that the residuals are normally distributed. A common threshold for significance is 0.05. Since the p-value is greater than 0.05, we do not have enough evidence to reject the null hypothesis, suggesting that the residuals are normally distributed.</p>\\n\\n<h3>Interpretation of the QQ Plot of Standardized Residuals</h3>\\n\\n<ul>\\n<li><strong>QQ Plot</strong>: This plot compares the quantiles of the standardized residuals against the quantiles of a normal distribution.</li>\\n<li><strong>45-Degree Line</strong>: Represents the expected line if the residuals are normally distributed.</li>\\n</ul>\\n\\n<p>In the plot, the points closely follow the 45-degree line, indicating that the residuals are approximately normally distributed. There are no significant deviations from the line, which supports the assumption of normality.</p>\\n\\n<p>Overall, both the Shapiro-Wilk test and the QQ plot suggest that the residuals are normally distributed, indicating that the assumption of normality is not violated in this regression model.</p>\\n',\n",
       " 'text27': \"<h3>Collinearity of Predictors</h3>\\n\\n<p>Collinearity, or multicollinearity, refers to a situation in regression analysis where two or more independent variables are highly correlated. This means that one predictor variable can be linearly predicted from the others with a substantial degree of accuracy. Collinearity can cause problems in estimating the coefficients of the regression model, leading to inflated standard errors, reduced statistical power, and difficulties in determining the individual effect of each predictor.</p>\\n\\n<h3>Variance Inflation Factor (VIF)</h3>\\n\\n<p>The Variance Inflation Factor (VIF) is a measure used to quantify the severity of multicollinearity in a regression model. It provides an index that measures how much the variance of an estimated regression coefficient increases when your predictors are correlated.</p>\\n\\n<h4>Mathematical Representation</h4>\\n\\n<p>The VIF for a predictor \\\\( X_j \\\\) is calculated as:</p>\\n\\n<p>\\\\(\\nVIF(X_j) = \\\\frac{1}{1 - R_j^2}\\n\\\\)</p>\\n\\n<p>Where:</p>\\n\\n<ul>\\n<li>\\\\( R_j^2 \\\\) is the coefficient of determination obtained by regressing \\\\( X_j \\\\) on all other predictors.</li>\\n</ul>\\n\\n<p>A VIF value of 1 indicates no correlation between the predictor and other variables, while a VIF value greater than 10 is often considered indicative of significant multicollinearity.</p>\\n\\n<p>Let's calculate the VIF for each predictor and plot the correlation matrix to check for collinearity.</p>\\n\",\n",
       " 'img28': 'image28.png',\n",
       " 'text28': '<h3>Interpretation of the Variance Inflation Factor (VIF)</h3>\\n\\n<p>The VIF values for the predictors are shown in the table. A VIF value greater than 10 is often considered indicative of significant multicollinearity. In this dataset, several variables have VIF values well above 10, suggesting that multicollinearity is a significant issue. For example, <code>fw_total</code> has a VIF of approximately 10295.27, indicating a high degree of multicollinearity.</p>\\n\\n<h3>Interpretation of the Correlation Matrix Plot</h3>\\n\\n<ul>\\n<li><strong>Heatmap</strong>: The plot shows the correlation coefficients between each pair of variables in the dataset. The color intensity indicates the strength of the correlation, with the color map ranging from blue (negative correlation) to red (positive correlation).</li>\\n<li><strong>Diagonal</strong>: The diagonal elements are all 1, as each variable is perfectly correlated with itself.</li>\\n<li><strong>Off-Diagonal Elements</strong>: These represent the correlation between different variables. High absolute values (close to 1 or -1) indicate strong correlations, which can contribute to multicollinearity.</li>\\n</ul>\\n\\n<h3>How to Read the Plot</h3>\\n\\n<ul>\\n<li><strong>Annotations</strong>: The numbers in each cell represent the correlation coefficient between the variables.</li>\\n<li><strong>Color Intensity</strong>: Darker colors indicate stronger correlations. Red indicates positive correlations, while blue indicates negative correlations.</li>\\n<li><strong>Focus on High Correlations</strong>: Look for cells with high absolute values (close to 1 or -1) to identify pairs of variables that may contribute to multicollinearity.</li>\\n</ul>\\n\\n<p>Overall, both the VIF values and the correlation matrix suggest that multicollinearity is a significant concern in this dataset, particularly for variables like <code>fw_total</code>, <code>dw_total</code>, and <code>dw_healthy</code>. This multicollinearity can affect the stability and interpretability of the regression model.</p>\\n',\n",
       " 'text29': \"<p>Here's a summary of the diagnostic results for the regression model:</p>\\n\\n<ol>\\n<li><p><strong>Outliers</strong>:</p>\\n\\n<ul>\\n<li>Identified using studentized residuals with a threshold of 3.</li>\\n<li>Observation with index 27 was identified as an outlier.</li>\\n</ul></li>\\n<li><p><strong>High-Leverage Points</strong>:</p>\\n\\n<ul>\\n<li>Identified using leverage values with a threshold of \\\\( \\\\frac{2p}{n} \\\\).</li>\\n<li>Observations with indices [20, 22, 26, 30, 36, 37, 42, 58, 74, 76, 106] were identified as high-leverage points.</li>\\n</ul></li>\\n<li><p><strong>Non-Linearity</strong>:</p>\\n\\n<ul>\\n<li>Assessed using the rainbow test and a residuals vs. fitted values plot.</li>\\n<li>The rainbow test did not indicate significant non-linearity (p-value &gt; 0.05).</li>\\n<li>The residuals plot showed no clear pattern, suggesting the linearity assumption is reasonably met.</li>\\n</ul></li>\\n<li><p><strong>Heteroscedasticity</strong>:</p>\\n\\n<ul>\\n<li>Assessed using the Breusch-Pagan test and a scale-location plot.</li>\\n<li>The Breusch-Pagan test did not indicate significant heteroscedasticity (p-value &gt; 0.05).</li>\\n<li>The scale-location plot showed no clear pattern, suggesting the homoscedasticity assumption is met.</li>\\n</ul></li>\\n<li><p><strong>Correlation of Error Terms</strong>:</p>\\n\\n<ul>\\n<li>Assessed using the Durbin-Watson test and a plot of residuals over time.</li>\\n<li>The Durbin-Watson statistic was slightly below the recommended range, indicating potential positive autocorrelation.</li>\\n<li>The residuals plot suggested some degree of autocorrelation.</li>\\n</ul></li>\\n<li><p><strong>Normality of Residuals</strong>:</p>\\n\\n<ul>\\n<li>Assessed using the Shapiro-Wilk test and a QQ plot.</li>\\n<li>The Shapiro-Wilk test did not indicate significant non-normality (p-value &gt; 0.05).</li>\\n<li>The QQ plot showed that residuals are approximately normally distributed.</li>\\n</ul></li>\\n<li><p><strong>Collinearity of Predictors</strong>:</p>\\n\\n<ul>\\n<li>Assessed using the Variance Inflation Factor (VIF) and a correlation matrix.</li>\\n<li>Several predictors had VIF values well above 10, indicating significant multicollinearity.</li>\\n<li>The correlation matrix showed strong correlations between some predictors.</li>\\n</ul></li>\\n</ol>\\n\\n<p>Overall, the diagnostics suggest that while the model meets assumptions of linearity, homoscedasticity, and normality, there are concerns with multicollinearity and potential autocorrelation in the error terms. Addressing these issues may improve the model's reliability and interpretability.</p>\\n\"}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chatgpt = []\n",
    "\n",
    "for i in range(len(response.data)):\n",
    "    if response.data[i].assistant_id:\n",
    "        output_chatgpt.append(response.data[i].content)\n",
    "        \n",
    "# output_chatgpt Muss Lnge 29 haben, sonst ist ein Fehler aufgetreten ---> noch einbauen!\n",
    "\n",
    "full_output_raw = output_chatgpt[::-1]\n",
    "full_output = {}\n",
    "\n",
    "for i in range(len(full_output_raw)):\n",
    "    if len(full_output_raw[i]) == 1 and i != 1:\n",
    "        text = full_output_raw[i][0].text.value.replace(r'\\[', r'\\\\(').replace(r'\\]', r'\\\\)').replace(r'\\(', r'\\\\(').replace(r'\\)', r'\\\\)')\n",
    "        full_output[f'text{i+1}'] = markdown2.markdown(text, extras=[\"code-friendly\", \"fenced-code-blocks\", \"cuddled-lists\"])\n",
    "    if len(full_output_raw[i]) == 1 and i == 1:\n",
    "        if i == 1:\n",
    "            # Formatting Table\n",
    "            html_table_raw = full_output_raw[i][0].text.value.replace(r'\\[', r'\\\\(').replace(r'\\]', r'\\\\)').replace(r'\\(', r'\\\\(').replace(r'\\)', r'\\\\)')\n",
    "            html_table_raw = html_table_raw.replace(\"```markdown\", \"\").replace(\"```\", \"\").strip()\n",
    "            lines = html_table_raw.split('\\n')\n",
    "            html_table1 = \"<table>\\n\"\n",
    "            # Process each line\n",
    "            for line in lines:\n",
    "                # Skip any empty lines\n",
    "                if line.strip():\n",
    "                    # Replace the Markdown table delimiters with HTML table tags\n",
    "                    if '---' in line:\n",
    "                        continue  # Skip the line with \"---\"\n",
    "                    elif '|' in line:\n",
    "                        line = line.replace('|', '</td><td>').strip('<td>').strip('</td>')\n",
    "                        html_table1 += f\"  <tr><td>{line}</td></tr>\\n\"\n",
    "            # Close the table tag\n",
    "            html_table1 += \"</table>\"\n",
    "            full_output[f'text{i+1}'] = html_table1\n",
    "    if len(full_output_raw[i]) == 2:\n",
    "        img_id = full_output_raw[i][0].image_file.file_id\n",
    "        image_data = client.files.content(img_id)\n",
    "        image_data_bytes = image_data.read()\n",
    "        with open(f\"image{i+1}.png\", \"wb\") as file:\n",
    "            file.write(image_data_bytes)\n",
    "        full_output[f'img{i+1}'] = f\"image{i+1}.png\"\n",
    "        text = full_output_raw[i][1].text.value.replace(r'\\[', r'\\\\(').replace(r'\\]', r'\\\\)').replace(r'\\(', r'\\\\(').replace(r'\\)', r'\\\\)')\n",
    "        full_output[f'text{i+1}'] = markdown2.markdown(text, extras=[\"code-friendly\", \"fenced-code-blocks\", \"cuddled-lists\"])\n",
    "    if len(full_output_raw[i]) == 3:\n",
    "        # first image\n",
    "        img_id = full_output_raw[i][0].image_file.file_id\n",
    "        image_data = client.files.content(img_id)\n",
    "        image_data_bytes = image_data.read()\n",
    "        with open(f\"image{i+1}.png\", \"wb\") as file:\n",
    "            file.write(image_data_bytes)\n",
    "        # secon image\n",
    "        img_id = full_output_raw[i][1].image_file.file_id\n",
    "        image_data = client.files.content(img_id)\n",
    "        image_data_bytes = image_data.read()\n",
    "        with open(f\"image{i+1}_2.png\", \"wb\") as file:\n",
    "            file.write(image_data_bytes)\n",
    "        full_output[f'img{i+1}'] = f\"image{i+1}.png\"\n",
    "        full_output[f'img{i+1}_2'] = f\"image{i+1}_2.png\"\n",
    "        text = full_output_raw[i][2].text.value.replace(r'\\[', r'\\\\(').replace(r'\\]', r'\\\\)').replace(r'\\(', r'\\\\(').replace(r'\\)', r'\\\\)')\n",
    "        full_output[f'text{i+1}'] = markdown2.markdown(text, extras=[\"code-friendly\", \"fenced-code-blocks\", \"cuddled-lists\"])\n",
    "        \n",
    "full_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_template = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Learning Regression Diagnostics</title>\n",
    "    <script src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\n",
    "    <script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n",
    "    <style>\n",
    "        table, th, td {{\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }}\n",
    "        th, td {{\n",
    "            padding: 8px;\n",
    "            text-align: left;\n",
    "        }}\n",
    "        .math {{\n",
    "            text-align: center;\n",
    "            margin: 1em 0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Part 1: Exploratory Data Analysis</h1>\n",
    "    <br>\n",
    "    <h2>What are Descriptive Statistics?</h2>\n",
    "    <p>{full_output['text1']}</p>\n",
    "    <br>\n",
    "    <h2>The Table of Descriptive Statistics</h2>\n",
    "\n",
    "    <div>\n",
    "        {full_output['text2']}\n",
    "    </div>\n",
    "    <p>{full_output['text3']}</p>\n",
    "    <br>\n",
    "    <h2>Visual Representation of the Data</h2>\n",
    "    <h3>Histograms</h3>\n",
    "    <p>{full_output['text4']}</p>\n",
    "    <img src=\"{full_output['img5']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    <p>{full_output['text5']}</p>\n",
    "    <br>\n",
    "    <h3>Boxplots</h3>\n",
    "    <p>{full_output['text6']}</p>\n",
    "    <img src=\"{full_output['img7']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    <p>{full_output['text7']}</p>\n",
    "    <br>\n",
    "    <h3>ECDF Plots</h3>\n",
    "    <p>{full_output['text8']}</p>\n",
    "    <img src=\"{full_output['text9']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    <p>{full_output['text9']}</p>\n",
    "    <br>\n",
    "    <h3>QQ-Plots</h3>\n",
    "    <p>{full_output['text10']}</p>\n",
    "    <img src=\"{full_output['img11']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    <p>{full_output['text11']}</p>\n",
    "    <br>\n",
    "    <h1>Part 2: The Multiple Linear Regression Model</h1>\n",
    "    <br>\n",
    "    <h2>What is Multiple Linear Regression?</h2>\n",
    "    {full_output['text12']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>What are Regression Diagnostics?</h2>\n",
    "    <p>{full_output['text13']}</p>\n",
    "    <br>\n",
    "    <p>{full_output['text14']}</p>\n",
    "    <br>\n",
    "    <h1>Part 3: Regression Diagnostics</h1>\n",
    "    <br>\n",
    "    <h2>Outliers</h2>\n",
    "    {full_output['text15']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img16']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text16']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>High-Leverage Points</h2>\n",
    "    {full_output['text17']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img18']}\" alt=\"Descriptive Statistics\" style=\"width:100%;;max-width: 1000px;\">\n",
    "    <br>\n",
    "    <img src=\"{full_output['img18_2']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text18']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Non-Linearity</h2>\n",
    "    {full_output['text19']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img20']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text20']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Heteroscedasticity</h2>\n",
    "    {full_output['text21']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img22']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text22']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Correlation of Error Terms</h2>\n",
    "    {full_output['text23']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img24']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text24']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Normality of Residuals</h2>\n",
    "    {full_output['text25']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img26']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text26']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Collinearity of Predictors</h2>\n",
    "    {full_output['text27']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <img src=\"{full_output['img28']}\" alt=\"Descriptive Statistics\" style=\"width:100%;max-width: 1000px;\">\n",
    "    {full_output['text28']}\n",
    "    <script>\n",
    "        MathJax.typeset();  // Renders the LaTeX after the page loads\n",
    "    </script>\n",
    "    <br>\n",
    "    <h2>Summary of Results</h2>\n",
    "    {full_output['text29']}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to an HTML file\n",
    "with open(\"ai_output.html\", \"w\") as file:\n",
    "    file.write(html_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
